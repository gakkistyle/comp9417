{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9417 19T3  Homework 2: Applying and Implementing Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 â€“ Learning curve \n",
    "\n",
    "The number of data instances required to effectively learn the target function depends on dataset characteristics and the learning algorithm. In this question, you will interpret results of learning three different datasets by two machine learning algorithms trained on varying size of data, from 5% to 90% of the dataset. After training on a fraction of the dataset, the model is tested using the rest of the dataset. For example, if 40% of data is used for training, the remaining 60% of the dataset is used for testing the trained model.\n",
    "The datasets are from different, real-world  domains, and vary in size from a few hundred to a couple of thousand instances. For a smoother learning curve, the training is done in a cross validation fashion.\n",
    "\n",
    "\n",
    "### Running the classifiers\n",
    "\n",
    "**1(a). [0.5 mark]** \n",
    "\n",
    "Run the code section in the notebook cells below. This will generate a table of results, which you should copy and paste **WITHOUT MODIFICATION** into you report as your answer for \"Question 1(a)\". \n",
    "\n",
    "The output of the code section is a table, which represents the percentage accuracy of classification for the decision tree algorithm. Each of the columns shows accuracy for a model trained on a different fraction of the dataset.\n",
    "\n",
    "### Result interpretation\n",
    "Answer these questions in your report file.  Your answers must be based on the results table you saved in \"Question 1(a)\".\n",
    "\n",
    "**1(b). [0.5 mark]** Refer to Homework2.pdf file.\n",
    "\n",
    "**1(c). [0.5 mark]** Refer to Homework2.pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for question 1\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed random seed\n",
    "np.random.seed(1)\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def label_enc(labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    dataset = arff.loadarff(path)\n",
    "    data = pd.DataFrame(dataset[0])\n",
    "    attr = np.array(data.columns)\n",
    "    data = DataFrameImputer().fit_transform(data).values\n",
    "\n",
    "    # mask categorical features\n",
    "    masks = []\n",
    "    for i in range(len(attr)-1):\n",
    "        if isinstance(attr[i][1],float):\n",
    "            masks.append(i)\n",
    "    return data, masks\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "def get_method_scores(data, method):\n",
    "    X = data[:,0:data.shape[1]-1]\n",
    "    lenc = label_enc(data[:,data.shape[1]-1])\n",
    "    y = lenc.transform(data[:,data.shape[1]-1])\n",
    "    train_sizes = np.array([0.05, .1, .15, .2, .25, .3, .35, .4, .45, .5])\n",
    "    _, train_scores, test_scores = learning_curve(method, X, y, cv=5, \n",
    "                                                  train_sizes=train_sizes,\n",
    "                                                  scoring=None, shuffle=False, random_state=0, \n",
    "                                                  error_score=0)\n",
    "    return test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DecisionTreeClassifier                           \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Dataset    |   5%   |  10%   |  15%   |  20%   |  25%   |  30%   |  35%   |  40%   |  45%   |  50%   |\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "australian    | 72.61% | 74.35% | 75.36% | 77.39% | 77.83% | 79.71% | 83.77% | 81.16% | 80.72% | 83.48% |\n",
      "balance-scale | 69.92% | 75.04% | 69.12% | 74.24% | 74.40% | 75.52% | 78.08% | 75.68% | 77.92% | 76.64% |\n",
      "hypothyroid   | 94.94% | 96.31% | 97.77% | 99.18% | 99.20% | 99.42% | 99.42% | 99.52% | 99.34% | 99.20% |\n",
      "\n",
      "\n",
      "                          BernoulliNB with priors                          \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Dataset    |   5%   |  10%   |  15%   |  20%   |  25%   |  30%   |  35%   |  40%   |  45%   |  50%   |\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "australian    | 73.48% | 79.86% | 81.45% | 80.43% | 79.71% | 79.86% | 79.86% | 81.16% | 82.17% | 81.88% |\n",
      "balance-scale | 46.08% | 46.08% | 46.08% | 46.08% | 46.24% | 46.08% | 46.08% | 46.24% | 46.24% | 46.08% |\n",
      "hypothyroid   | 91.38% | 91.81% | 92.23% | 92.23% | 92.23% | 92.26% | 92.23% | 92.23% | 92.23% | 92.23% |\n",
      "\n",
      "\n",
      "                        BernoulliNB without priors                         \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "   Dataset    |   5%   |  10%   |  15%   |  20%   |  25%   |  30%   |  35%   |  40%   |  45%   |  50%   |\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "australian    | 73.62% | 79.42% | 81.45% | 78.99% | 78.12% | 78.55% | 78.70% | 80.00% | 80.43% | 80.58% |\n",
      "balance-scale | 46.08% | 46.08% | 46.08% | 46.08% | 46.24% | 46.08% | 46.08% | 46.24% | 46.24% | 46.08% |\n",
      "hypothyroid   | 83.51% | 79.51% | 77.44% | 74.82% | 68.48% | 64.54% | 54.03% | 51.25% | 51.06% | 50.82% |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_method(method, title):\n",
    "    # load data\n",
    "    paths = ['australian','balance-scale','hypothyroid']\n",
    "    scores = []\n",
    "\n",
    "    for path in paths:\n",
    "        score = []\n",
    "        path += '.arff'\n",
    "        data, masks = load_data(path)\n",
    "\n",
    "        # training on data with different portions of training data\n",
    "        score_array = get_method_scores(data, method)\n",
    "        # we got a [num portions][num folds] array, need to avg them into \n",
    "        # a list of scores for each portion\n",
    "        for ar in score_array:\n",
    "            score.append(np.mean(ar))\n",
    "        scores.append(score)\n",
    "\n",
    "    # print the results\n",
    "    method_name = method.__class__.__name__+' '+title\n",
    "    header = \"{:^75}\".format(method_name) + '\\n' + '-' * 105  + '\\n' + \\\n",
    "    \"{:^13} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} | {:^6} |\" \\\n",
    "    .format(\"Dataset\", \"5%\", \"10%\", \"15%\", \"20%\", \"25%\", \"30%\", \"35%\", \"40%\", \"45%\", \"50%\") + \\\n",
    "     '\\n' + '-' * 105\n",
    "\n",
    "    # print result table\n",
    "    print(header)\n",
    "    for i in range(len(scores)):\n",
    "        print(\"{:<14}\".format(paths[i]),end=\"\")\n",
    "        for j in range(len(scores[i])):\n",
    "            print(\"| {:>6.2%} \".format(scores[i][j]),end=\"\")\n",
    "        print('|')\n",
    "    print('\\n')\n",
    "\n",
    "test_method(DecisionTreeClassifier(random_state=0),'')\n",
    "test_method(BernoulliNB(),'with priors')\n",
    "test_method(BernoulliNB(fit_prior=False),'without priors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
